#!/usr/bin/env python3
"""
å®Œæ•´çš„1551ä¸ªAPIå¤„ç†å™¨ - ç”Ÿæˆå…¨é¢çš„APIå®ç°æ˜ å°„è¡¨
ä¼˜åŒ–çš„ç‰ˆæœ¬ï¼Œä¸“é—¨å¤„ç†æ‰€æœ‰é£ä¹¦å¼€æ”¾å¹³å°API
"""

import csv
import re
import os
import subprocess
from pathlib import Path
import time
import json
from datetime import datetime

class APIProcessor:
    def __init__(self):
        self.results = []
        self.found_count = 0
        self.processed_count = 0
        self.start_time = None
        self.service_stats = {}

    def extract_service_info(self, path):
        """æå–æœåŠ¡ä¿¡æ¯çš„ç‹¬ç«‹æ–¹æ³•"""
        path_parts = path.strip('/').split('/')
        if len(path_parts) >= 2 and path_parts[0] == 'open-apis':
            service = path_parts[1]
            version = 'v1'
            for part in path_parts[1:]:
                if part.startswith('v') and part[1:].isdigit():
                    version = part
                    break
            return service, version
        return 'unknown', 'v1'

    def update_service_stats(self, service, found):
        """ç»Ÿä¸€çš„æœåŠ¡ç»Ÿè®¡æ›´æ–°æ–¹æ³•"""
        if service not in self.service_stats:
            self.service_stats[service] = {
                'found': 0,
                'total': 0,
                'rate': 0.0
            }

        self.service_stats[service]['total'] += 1
        if found:
            self.service_stats[service]['found'] += 1

        # å®æ—¶è®¡ç®—å®ç°ç‡
        self.service_stats[service]['rate'] = (
            self.service_stats[service]['found'] /
            self.service_stats[service]['total'] * 100
        )

    def find_api_implementation_optimized(self, api_name, method, path):
        """ä¼˜åŒ–çš„APIå®ç°æŸ¥æ‰¾"""

        # ä½¿ç”¨æ–°çš„æœåŠ¡ä¿¡æ¯æå–æ–¹æ³•
        service_name, version = self.extract_service_info(path)

        # ä»è·¯å¾„æå–service_partsç”¨äºå…³é”®è¯æœç´¢
        path_parts = path.strip('/').split('/')
        service_parts = path_parts[1:] if len(path_parts) >= 2 and path_parts[0] == 'open-apis' else path_parts

        # ä¼˜å…ˆæœç´¢çš„æœåŠ¡ç›®å½•è·¯å¾„
        search_dirs = []
        if service_name != 'unknown':
            search_dirs.extend([
                f"../src/service/{service_name}/",
                f"../src/service/{service_name}/{version}/"
            ])

        # æ„å»ºæœç´¢å…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        keywords = []

        # 1. ä»è·¯å¾„æœ€åéƒ¨åˆ†æå–
        if service_parts:
            last_part = service_parts[-1]
            clean_last = re.sub(r'[^a-zA-Z0-9_]', '', last_part)
            if clean_last:
                keywords.append(clean_last)

        # 2. ä»APIåç§°æå–å…³é”®è¯
        name_parts = re.sub(r'(è·å–|åˆ›å»º|åˆ é™¤|æ›´æ–°|ä¿®æ”¹|æŸ¥è¯¢|æœç´¢)', '', api_name)
        name_parts = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fff]', '', name_parts)
        if len(name_parts) >= 2:
            keywords.append(name_parts)

        # 3. HTTPæ–¹æ³• + è·¯å¾„ç»„åˆ
        if service_parts:
            http_combo = f"{method.lower()}_{service_parts[-1]}"
            http_combo = re.sub(r'[^a-zA-Z0-9_]', '', http_combo)
            keywords.append(http_combo)

        # 4. åŸºäºæœåŠ¡åçš„æœç´¢
        if service_name != 'unknown':
            keywords.append(service_name)

        # 5. ç‰¹æ®Šæ˜ å°„è§„åˆ™ï¼ˆæé«˜å‡†ç¡®æ€§ï¼‰
        special_mappings = {
            'user_info': ['user_info'],
            'tenant_access_token': ['tenant_access_token'],
            'app_access_token': ['app_access_token'],
            'app_ticket': ['app_ticket'],
            'message': ['message', 'send_message'],
            'users': ['user'],
            'departments': ['department'],
            'employee': ['employee'],
            'sessions': ['session'],
            'scopes': ['scope'],
            'groups': ['group'],
            'roles': ['role'],
            'files': ['file'],
            'sheets': ['sheet'],
            'tasks': ['task'],
            'events': ['event'],
            'comments': ['comment'],
            'approval': ['approval'],
            'calendar': ['calendar'],
            'meeting': ['meeting'],
            'sheets': ['sheets'],
            'bitable': ['bitable']
        }

        for special_key, special_keywords in special_mappings.items():
            if special_key in path.lower() or special_key in api_name.lower():
                keywords.extend(special_keywords)

        # å»é‡å¹¶é™åˆ¶å…³é”®è¯æ•°é‡
        keywords = list(dict.fromkeys(keywords))[:5]

        # åœ¨æœ€å¯èƒ½çš„ç›®å½•ä¸­æœç´¢
        for search_dir in search_dirs:
            if not os.path.exists(search_dir):
                continue

            for keyword in keywords:
                try:
                    # æœç´¢ç›¸å…³å‡½æ•°
                    cmd = [
                        "grep", "-r", "-n", "--include=*.rs",
                        f"pub async fn.*{keyword}",
                        search_dir
                    ]

                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=2)
                    if result.returncode == 0 and result.stdout.strip():
                        lines = result.stdout.strip().split('\n')
                        for line in lines[:1]:  # åªå–ç¬¬ä¸€ä¸ªæœ€ä½³åŒ¹é…
                            if ':' in line and 'pub async fn' in line:
                                parts = line.split(':', 2)
                                if len(parts) >= 3:
                                    file_path = parts[0]
                                    line_num = parts[1]
                                    content = parts[2].strip()

                                    if os.path.exists(file_path):
                                        rel_path = os.path.relpath(file_path, os.getcwd())
                                        # æ›´æ–°æœåŠ¡ç»Ÿè®¡
                                        if service_name not in self.service_stats:
                                            self.service_stats[service_name] = {'found': 0, 'total': 0}
                                        return rel_path, line_num, content
                except (subprocess.TimeoutExpired, Exception):
                    continue

        # å¦‚æœç²¾ç¡®æœç´¢å¤±è´¥ï¼Œåœ¨src/serviceç›®å½•ä¸­å¹¿æ³›æœç´¢
        try:
            broader_cmd = [
                "grep", "-r", "-n", "--include=*.rs",
                f"pub async fn.*{keywords[0] if keywords else service_name}",
                "../src/service/"
            ]

            result = subprocess.run(broader_cmd, capture_output=True, text=True, timeout=3)
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines[:2]:  # å°è¯•å‰2ä¸ªç»“æœ
                    if ':' in line and 'pub async fn' in line:
                        parts = line.split(':', 2)
                        if len(parts) >= 3:
                            file_path = parts[0]
                            line_num = parts[1]
                            content = parts[2].strip()
                            if os.path.exists(file_path):
                                rel_path = os.path.relpath(file_path, os.getcwd())
                                return rel_path, line_num, content
        except Exception:
            pass

        return None, None, None

    def process_single_api(self, api, index, total):
        """å¤„ç†å•ä¸ªAPI"""
        try:
            file_path, line_num, content = self.find_api_implementation_optimized(
                api['name'], api['method'], api['path']
            )

            # æå–æœåŠ¡ä¿¡æ¯å¹¶æ›´æ–°ç»Ÿè®¡
            service, _ = self.extract_service_info(api['path'])
            found = file_path is not None

            # ä½¿ç”¨ç»Ÿä¸€çš„ç»Ÿè®¡æ›´æ–°æ–¹æ³•
            self.update_service_stats(service, found)

            if found:
                self.found_count += 1

                result = {
                    **api,
                    'file_path': file_path,
                    'line_number': line_num,
                    'implementation_preview': content[:50] + "..." if len(content) > 50 else content,
                    'status': 'found'
                }
            else:
                result = {
                    **api,
                    'file_path': "æœªæ‰¾åˆ°",
                    'line_number': "-",
                    'implementation_preview': "-",
                    'status': 'not_found'
                }

            self.results.append(result)
            self.processed_count += 1

            # è¿›åº¦æŠ¥å‘Š
            if index % 100 == 0 or index == total:
                elapsed = time.time() - self.start_time
                rate = index / elapsed if elapsed > 0 else 0
                remaining = (total - index) / rate if rate > 0 else 0
                progress_pct = (index / total) * 100
                found_rate = (self.found_count / index) * 100 if index > 0 else 0

                print(f"è¿›åº¦: {index}/{total} ({progress_pct:.1f}%) - "
                      f"æ‰¾åˆ°å®ç°: {self.found_count} ({found_rate:.1f}%) - "
                      f"é€Ÿåº¦: {rate:.1f} API/s - é¢„è®¡å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")

        except Exception as e:
            print(f"å¤„ç†API {api['name']} æ—¶å‡ºé”™: {e}")

    def process_all_apis(self):
        """å¤„ç†æ‰€æœ‰API"""
        csv_file = "server_api_list.csv"
        output_file = "../complete_all_api_implementation_map.md"
        json_file = "../api_implementation_data.json"

        if not os.path.exists(csv_file):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {csv_file}")
            return

        print(f"å¼€å§‹å¤„ç†å®Œæ•´çš„APIåˆ—è¡¨...")
        self.start_time = time.time()

        # è¯»å–æ‰€æœ‰API
        apis = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)  # è·³è¿‡æ ‡é¢˜è¡Œ

            for row in reader:
                if len(row) >= 7:
                    name, method, path, desc, self_build, store_app, doc_link = row[:7]
                    apis.append({
                        'name': name,
                        'method': method,
                        'path': path,
                        'description': desc,
                        'self_build': self_build,
                        'store_app': store_app,
                        'doc_link': doc_link
                    })

        print(f"æ€»å…±è¯»å–åˆ° {len(apis)} ä¸ªAPI")

        # å¤„ç†æ‰€æœ‰API
        for i, api in enumerate(apis, 1):
            self.process_single_api(api, i, len(apis))

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_reports(len(apis), output_file, json_file)

    def analyze_service_coverage(self):
        """åˆ†ææœåŠ¡è¦†ç›–ç‡"""
        analysis = {
            'high_coverage': [],    # å®ç°ç‡ >= 80%
            'medium_coverage': [],  # å®ç°ç‡ 50-79%
            'low_coverage': [],     # å®ç°ç‡ < 50%
            'no_coverage': []       # å®ç°ç‡ = 0%
        }

        for service, stats in self.service_stats.items():
            if stats['total'] == 0:
                continue

            rate = stats['rate']
            service_info = {
                'name': service,
                'found': stats['found'],
                'total': stats['total'],
                'rate': rate
            }

            if rate >= 80:
                analysis['high_coverage'].append(service_info)
            elif rate >= 50:
                analysis['medium_coverage'].append(service_info)
            elif rate > 0:
                analysis['low_coverage'].append(service_info)
            else:
                analysis['no_coverage'].append(service_info)

        return analysis

    def generate_module_grouped_report(self, f, sorted_services):
        """ç”ŸæˆæŒ‰æ¨¡å—åˆ†ç»„çš„æŠ¥å‘Š"""
        f.write("\n\n## æŒ‰æ¨¡å—åˆ†ç»„çš„APIå®ç°æƒ…å†µ\n\n")

        for service, stats in sorted_services:
            if stats['total'] == 0:
                continue

            # æ¨¡å—æ ‡é¢˜
            rate = stats['rate']
            status_emoji = "ğŸŸ¢" if rate >= 80 else "ğŸŸ¡" if rate >= 50 else "ğŸ”´"
            f.write(f"### {status_emoji} {service.upper()} æ¨¡å— ({stats['found']}/{stats['total']} - {rate:.1f}%)\n\n")

            # è¯¥æ¨¡å—çš„APIåˆ—è¡¨
            module_apis = [r for r in self.results
                          if self.extract_service_info(r['path'])[0] == service]

            if module_apis:
                f.write("| åºå· | APIåç§° | è¯·æ±‚æ–¹å¼ | APIåœ°å€ | çŠ¶æ€ |\n")
                f.write("|------|---------|----------|---------|------|\n")

                for i, api in enumerate(module_apis, 1):
                    name = api['name'].replace('|', '\\|')
                    method = api['method']
                    path = api['path'].replace('|', '\\|')
                    status = "âœ…" if api['status'] == 'found' else "âŒ"

                    f.write(f"| {i} | {name} | {method} | `{path}` | {status} |\n")

                f.write("\n")

    def generate_summary_report(self, f):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        analysis = self.analyze_service_coverage()

        f.write("## å®ç°è¦†ç›–ç‡åˆ†æ\n\n")
        f.write(f"ğŸŸ¢ **é«˜è¦†ç›–ç‡æ¨¡å— (â‰¥80%)**: {len(analysis['high_coverage'])} ä¸ª\n")
        f.write(f"ğŸŸ¡ **ä¸­ç­‰è¦†ç›–ç‡æ¨¡å— (50-79%)**: {len(analysis['medium_coverage'])} ä¸ª\n")
        f.write(f"ğŸ”´ **ä½è¦†ç›–ç‡æ¨¡å— (<50%)**: {len(analysis['low_coverage'])} ä¸ª\n")
        f.write(f"âš« **é›¶è¦†ç›–ç‡æ¨¡å—**: {len(analysis['no_coverage'])} ä¸ª\n\n")

        # ä¼˜å…ˆæ”¹è¿›å»ºè®®
        if analysis['low_coverage']:
            f.write("### ğŸš€ ä¼˜å…ˆæ”¹è¿›å»ºè®®\n\n")
            f.write("ä»¥ä¸‹æ¨¡å—å®ç°ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆå®Œå–„ï¼š\n\n")
            for service in sorted(analysis['low_coverage'], key=lambda x: x['rate'])[:5]:
                f.write(f"- **{service['name']}**: {service['found']}/{service['total']} ({service['rate']:.1f}%)\n")

    def generate_reports(self, total_apis, md_file, json_file):
        """ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶"""
        total_time = time.time() - self.start_time
        print(f"\nå¤„ç†å®Œæˆï¼")
        print(f"- æ€»APIæ•°: {total_apis}")
        print(f"- æ‰¾åˆ°å®ç°: {self.found_count}")
        print(f"- å®ç°ç‡: {self.found_count/total_apis*100:.1f}%")
        print(f"- æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        print(f"- å¹³å‡é€Ÿåº¦: {total_apis/total_time:.1f} API/ç§’")

        # ä¿å­˜JSONæ•°æ®
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'total_apis': total_apis,
                    'found_count': self.found_count,
                    'implementation_rate': self.found_count/total_apis*100,
                    'processing_time': total_time,
                    'generated_at': datetime.now().isoformat()
                },
                'service_stats': self.service_stats,
                'results': self.results
            }, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        print(f"\nç”ŸæˆMarkdownæŠ¥å‘Š...")
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write("# å®Œæ•´APIå®ç°æ˜ å°„è¡¨\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
            f.write(f"**æ€»APIæ•°**: {total_apis}  \n")
            f.write(f"**å·²å®ç°**: {self.found_count}  \n")
            f.write(f"**å®ç°ç‡**: {self.found_count/total_apis*100:.1f}%  \n")
            f.write(f"**å¤„ç†è€—æ—¶**: {total_time/60:.1f} åˆ†é’Ÿ  \n")
            f.write(f"**å¤„ç†é€Ÿåº¦**: {total_apis/total_time:.1f} API/ç§’  \n\n")

            f.write("| åºå· | APIåç§° | è¯·æ±‚æ–¹å¼ | APIåœ°å€ | æ–‡æ¡£é“¾æ¥ | æ–‡ä»¶è·¯å¾„ | è¡Œå· | çŠ¶æ€ |\n")
            f.write("|------|---------|----------|---------|----------|----------|------|------|\n")

            for i, result in enumerate(self.results, 1):
                raw_name = result['name']
                name = raw_name.replace('|', '\\|')
                method = result['method']
                path = result['path'].replace('|', '\\|')
                file_path = result['file_path'].replace('|', '\\|')
                line_num = result['line_number']
                status = "âœ… å·²å®ç°" if result['status'] == 'found' else "âŒ æœªå®ç°"
                doc_link = result.get('doc_link', '') or ''
                doc_cell = doc_link.replace('|', '\\|') if doc_link else "-"
                if doc_link:
                    name_cell = f"[{name}]({doc_cell})"
                else:
                    name_cell = name

                f.write(
                    f"| {i} | {name_cell} | {method} | `{path}` | {doc_cell} | `{file_path}` | {line_num} | {status} |\n"
                )

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            f.write("\n\n## å®ç°ç»Ÿè®¡\n\n")

            # æ”¹è¿›çš„æ’åºé€»è¾‘ï¼šæŒ‰å®ç°ç‡æ’åºï¼Œå®ç°ç‡ç›¸åŒçš„æŒ‰æœåŠ¡åæ’åº
            sorted_services = sorted(
                self.service_stats.items(),
                key=lambda x: (-x[1]['rate'], x[0])  # å®ç°ç‡é™åºï¼ŒæœåŠ¡åå‡åº
            )

            # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            self.generate_summary_report(f)

            # ç”ŸæˆæŒ‰æ¨¡å—åˆ†ç»„çš„è¯¦ç»†æŠ¥å‘Š
            self.generate_module_grouped_report(f, sorted_services)

            # æœªå®ç°çš„API
            not_found = [r for r in self.results if r['status'] == 'not_found']
            if not_found:
                f.write(f"\n### æœªå®ç°çš„API ({len(not_found)}ä¸ª)\n\n")
                f.write("ä»¥ä¸‹æ˜¯å‰100ä¸ªæœªå®ç°çš„API:\n\n")
                for api in not_found[:100]:
                    f.write(f"- {api['name']} ({api['method']} {api['path']})\n")
                if len(not_found) > 100:
                    f.write(f"- ... è¿˜æœ‰ {len(not_found) - 100} ä¸ªæœªå®ç°çš„API\n")

        print(f"å®Œæ•´APIæ˜ å°„è¡¨å·²ä¿å­˜åˆ°: {md_file}")
        print(f"è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°: {json_file}")

if __name__ == "__main__":
    processor = APIProcessor()
    processor.process_all_apis()
