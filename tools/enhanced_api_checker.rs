#!/usr/bin/env cargo run --bin

//! # å¢å¼ºç‰ˆAPIè®¾è®¡ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·
//!
//! æä¾›è¯¦ç»†çš„APIåˆ†æã€é—®é¢˜è¯†åˆ«å’Œæ”¹è¿›å»ºè®®ç”ŸæˆåŠŸèƒ½

use std::{collections::HashMap, fs, path::Path};
use walkdir::WalkDir;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ”§ å¢å¼ºç‰ˆAPIè®¾è®¡ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·");
    println!("=====================================\n");

    let service_dir = "src/service";
    let mut results = HashMap::new();

    println!("ğŸ” æ‰«ææœåŠ¡ç›®å½•: {service_dir}");

    // æ‰«ææ‰€æœ‰æœåŠ¡æ–‡ä»¶
    for entry in WalkDir::new(service_dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.path().extension().is_some_and(|ext| ext == "rs"))
    {
        let path = entry.path();
        if let Ok(content) = fs::read_to_string(path) {
            let analysis = analyze_file_enhanced(&content, path);
            results.insert(path.to_string_lossy().to_string(), analysis);
        }
    }

    println!("ğŸ“Š åˆ†æç»“æœ:");
    println!("æ£€æŸ¥äº† {} ä¸ªæ–‡ä»¶\n", results.len());

    // ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡
    generate_detailed_statistics(&results);

    // è¯†åˆ«é—®é¢˜å’Œç”Ÿæˆå»ºè®®
    let issues = identify_issues(&results);
    display_issues(&issues);

    // ç”Ÿæˆå¢å¼ºæŠ¥å‘Š
    let report_path = "reports/enhanced_api_consistency_report.md";
    generate_enhanced_report(&results, &issues, report_path)?;
    println!("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}");

    Ok(())
}

#[derive(Debug, Clone)]
#[allow(dead_code)]
struct EnhancedFileAnalysis {
    file_path: String,
    method_count: u32,
    builder_patterns: u32,
    standard_response_usage: u32,
    documentation_count: u32,
    // æ–°å¢å­—æ®µ
    method_details: Vec<MethodInfo>,
    has_proper_error_handling: bool,
    api_patterns: Vec<APIPattern>,
    complexity_score: u32,
    improvement_priority: Priority,
}

#[derive(Debug, Clone)]
#[allow(dead_code)]
struct MethodInfo {
    name: String,
    line_number: usize,
    is_async: bool,
    has_builder: bool,
    uses_standard_response: bool,
    parameter_count: u32,
    return_type: String,
    has_documentation: bool,
}

#[derive(Debug, Clone)]
enum APIPattern {
    Crud,
    Query,
    Upload,
    Batch,
    Stream,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
enum Priority {
    Critical, // éœ€è¦ç«‹å³ä¿®å¤
    High,     // é«˜ä¼˜å…ˆçº§æ”¹è¿›
    Medium,   // ä¸­ç­‰ä¼˜å…ˆçº§
    Low,      // ä½ä¼˜å…ˆçº§
}

#[derive(Debug, Clone)]
struct Issue {
    file_path: String,
    issue_type: IssueType,
    description: String,
    severity: Priority,
    suggestion: String,
    example_fix: Option<String>,
}

#[derive(Debug, Clone)]
#[allow(dead_code)]
enum IssueType {
    MissingStandardResponse,
    MissingBuilderPattern,
    PoorDocumentation,
    InconsistentNaming,
    ComplexParameters,
}

fn analyze_file_enhanced(content: &str, path: &Path) -> EnhancedFileAnalysis {
    let file_path = path.to_string_lossy().to_string();

    // åŸºç¡€ç»Ÿè®¡ï¼ˆä¿æŒä¸ç®€åŒ–ç‰ˆå…¼å®¹ï¼‰
    let method_count =
        content.matches("pub fn").count() as u32 + content.matches("pub async fn").count() as u32;
    let builder_patterns = count_builder_patterns(content);
    let standard_response_usage = count_standard_response_usage(content);
    let documentation_count = content.matches("///").count() as u32;

    // å¢å¼ºåˆ†æ
    let method_details = extract_method_details(content);
    let has_proper_error_handling = check_error_handling(content);
    let api_patterns = identify_api_patterns(content, path);
    let complexity_score = calculate_complexity_score(&method_details, content);
    let improvement_priority =
        determine_priority(method_count, standard_response_usage, &method_details);

    EnhancedFileAnalysis {
        file_path,
        method_count,
        builder_patterns,
        standard_response_usage,
        documentation_count,
        method_details,
        has_proper_error_handling,
        api_patterns,
        complexity_score,
        improvement_priority,
    }
}

fn count_builder_patterns(content: &str) -> u32 {
    let mut count = 0;

    // æ›´ç²¾ç¡®çš„Builderæ¨¡å¼æ£€æµ‹
    if content.contains("Builder {") || content.contains("Builder<") {
        count += content.matches("Builder").count() as u32;
    }

    // æ£€æŸ¥builder()æ–¹æ³•
    count += content.matches("pub fn builder()").count() as u32;
    count += content.matches(".builder()").count() as u32;

    // æ£€æŸ¥å…¸å‹çš„Builderæ–¹æ³•
    for method in ["build()", "with_", "set_"] {
        if content.contains(method) {
            count += 1;
            break;
        }
    }

    count
}

fn count_standard_response_usage(content: &str) -> u32 {
    let mut count = 0;

    // ç²¾ç¡®æ£€æµ‹.into_result()è°ƒç”¨
    count += content.matches(".into_result()").count() as u32;

    // æ£€æŸ¥StandardResponse traitä½¿ç”¨
    if content.contains("use crate::core::standard_response::StandardResponse")
        || content.contains("StandardResponse")
    {
        count += 1;
    }

    count
}

fn extract_method_details(content: &str) -> Vec<MethodInfo> {
    let mut methods = Vec::new();
    let lines: Vec<&str> = content.lines().collect();

    for (line_num, line) in lines.iter().enumerate() {
        if line.trim_start().starts_with("pub async fn")
            || (line.trim_start().starts_with("pub fn") && !line.contains(" new("))
        {
            let method_info = parse_method_signature(line, line_num + 1, &lines);
            methods.push(method_info);
        }
    }

    methods
}

fn parse_method_signature(line: &str, line_number: usize, lines: &[&str]) -> MethodInfo {
    let is_async = line.contains("async");
    let name = extract_method_name(line);

    // æ£€æŸ¥æ–¹æ³•æ˜¯å¦æœ‰builderæ”¯æŒï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
    let has_builder = line.contains("builder")
        || lines
            .iter()
            .any(|l| l.contains(&format!("{}Builder", name)));

    // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨StandardResponse
    let uses_standard_response = lines
        .iter()
        .skip(line_number.saturating_sub(1))
        .take(20) // æ£€æŸ¥æ–¹æ³•ä½“å‰20è¡Œ
        .any(|l| l.contains(".into_result()"));

    // ä¼°ç®—å‚æ•°æ•°é‡ï¼ˆç®€åŒ–å®ç°ï¼‰
    let parameter_count = count_parameters(line);

    // æå–è¿”å›ç±»å‹
    let return_type = extract_return_type(line);

    // æ£€æŸ¥æ–‡æ¡£æ³¨é‡Šï¼ˆæ£€æŸ¥æ–¹æ³•å‰çš„æ³¨é‡Šï¼‰
    let has_documentation = line_number > 1
        && lines
            .get(line_number.saturating_sub(2))
            .is_some_and(|prev_line| prev_line.trim_start().starts_with("///"));

    MethodInfo {
        name: name.to_string(),
        line_number,
        is_async,
        has_builder,
        uses_standard_response,
        parameter_count,
        return_type,
        has_documentation,
    }
}

fn extract_method_name(line: &str) -> &str {
    if let Some(start) = line.find("fn ") {
        let after_fn = &line[start + 3..];
        if let Some(end) = after_fn.find('(') {
            return after_fn[..end].trim();
        }
    }
    "unknown"
}

fn count_parameters(line: &str) -> u32 {
    // ç®€åŒ–çš„å‚æ•°è®¡æ•°ï¼Œé€šè¿‡é€—å·æ•°é‡ä¼°ç®—
    let param_part = if let Some(start) = line.find('(') {
        if let Some(end) = line.find(')') {
            &line[start + 1..end]
        } else {
            ""
        }
    } else {
        ""
    };

    if param_part.trim().is_empty() || param_part.trim() == "&self" {
        0
    } else {
        // æ’é™¤&selfï¼Œè®¡ç®—å…¶ä»–å‚æ•°
        let params = param_part.split(',').count() as u32;
        if param_part.contains("&self") {
            params.saturating_sub(1)
        } else {
            params
        }
    }
}

fn extract_return_type(line: &str) -> String {
    if let Some(arrow_pos) = line.find("-> ") {
        let return_part = &line[arrow_pos + 3..];
        if let Some(brace_pos) = return_part.find(" {") {
            return_part[..brace_pos].trim().to_string()
        } else {
            return_part.trim().to_string()
        }
    } else {
        "()".to_string()
    }
}

fn check_error_handling(content: &str) -> bool {
    // æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†
    content.contains("SDKResult")
        || content.contains("Result<")
        || content.contains(".into_result()")
        || content.contains("LarkAPIError")
}

fn identify_api_patterns(content: &str, path: &Path) -> Vec<APIPattern> {
    let mut patterns = Vec::new();
    let path_str = path.to_string_lossy().to_lowercase();

    // æ ¹æ®æ–‡ä»¶åå’Œå†…å®¹è¯†åˆ«APIæ¨¡å¼
    if path_str.contains("create") || content.contains("pub fn create") || content.contains("POST")
    {
        patterns.push(APIPattern::Crud);
    }

    if path_str.contains("list")
        || path_str.contains("search")
        || content.contains("pub fn list")
        || content.contains("pub fn search")
    {
        patterns.push(APIPattern::Query);
    }

    if path_str.contains("upload") || content.contains("multipart") || content.contains("file") {
        patterns.push(APIPattern::Upload);
    }

    if content.contains("batch") || path_str.contains("batch") {
        patterns.push(APIPattern::Batch);
    }

    if content.contains("stream") || content.contains("WebSocket") {
        patterns.push(APIPattern::Stream);
    }

    patterns
}

fn calculate_complexity_score(methods: &[MethodInfo], content: &str) -> u32 {
    let mut score = 0;

    // æ–¹æ³•æ•°é‡è´¡çŒ®
    score += methods.len() as u32;

    // å¤æ‚å‚æ•°è´¡çŒ®
    for method in methods {
        score += method.parameter_count;
    }

    // å†…å®¹å¤æ‚åº¦
    score += (content.len() / 1000) as u32; // æ¯1000å­—ç¬¦+1åˆ†

    // åµŒå¥—ç»“æ„å¤æ‚åº¦
    score += content.matches("impl").count() as u32;
    score += content.matches("struct").count() as u32;
    score += content.matches("enum").count() as u32;

    score
}

fn determine_priority(
    method_count: u32,
    standard_response_usage: u32,
    _methods: &[MethodInfo],
) -> Priority {
    let sr_coverage = if method_count > 0 {
        (standard_response_usage as f32 / method_count as f32) * 100.0
    } else {
        0.0
    };

    // æ ¹æ®StandardResponseè¦†ç›–ç‡å’Œæ–¹æ³•æ•°é‡ç¡®å®šä¼˜å…ˆçº§
    if method_count > 0 && sr_coverage < 10.0 {
        if method_count > 20 {
            Priority::Critical
        } else if method_count > 10 {
            Priority::High
        } else {
            Priority::Medium
        }
    } else if sr_coverage < 50.0 {
        Priority::Medium
    } else {
        Priority::Low
    }
}

fn identify_issues(results: &HashMap<String, EnhancedFileAnalysis>) -> Vec<Issue> {
    let mut issues = Vec::new();

    for analysis in results.values() {
        // æ£€æŸ¥StandardResponseä½¿ç”¨æƒ…å†µ
        if analysis.method_count > 0 {
            let sr_coverage =
                (analysis.standard_response_usage as f32 / analysis.method_count as f32) * 100.0;

            if sr_coverage < 80.0 {
                issues.push(Issue {
                    file_path: analysis.file_path.clone(),
                    issue_type: IssueType::MissingStandardResponse,
                    description: format!(
                        "StandardResponseè¦†ç›–ç‡ä»…{:.1}%ï¼Œåº”è¯¥ä½¿ç”¨.into_result()ç»Ÿä¸€é”™è¯¯å¤„ç†",
                        sr_coverage
                    ),
                    severity: if sr_coverage < 20.0 {
                        Priority::Critical
                    } else {
                        Priority::High
                    },
                    suggestion: "ä¸ºæ‰€æœ‰APIæ–¹æ³•æ·»åŠ .into_result()è°ƒç”¨ï¼Œç»Ÿä¸€å“åº”å¤„ç†".to_string(),
                    example_fix: Some(generate_standard_response_example()),
                });
            }
        }

        // æ£€æŸ¥Builderæ¨¡å¼
        let complex_methods = analysis
            .method_details
            .iter()
            .filter(|m| m.parameter_count > 3)
            .count();

        if complex_methods > 0 && analysis.builder_patterns == 0 {
            issues.push(Issue {
                file_path: analysis.file_path.clone(),
                issue_type: IssueType::MissingBuilderPattern,
                description: format!("æœ‰{}ä¸ªå¤æ‚å‚æ•°æ–¹æ³•æœªä½¿ç”¨Builderæ¨¡å¼", complex_methods),
                severity: Priority::Medium,
                suggestion: "ä¸ºå¤æ‚å‚æ•°çš„æ–¹æ³•æ·»åŠ Builderæ”¯æŒï¼Œæå‡æ˜“ç”¨æ€§".to_string(),
                example_fix: Some(generate_builder_example()),
            });
        }

        // æ£€æŸ¥æ–‡æ¡£è¦†ç›–ç‡
        let documented_methods = analysis
            .method_details
            .iter()
            .filter(|m| m.has_documentation)
            .count();
        let doc_coverage = if analysis.method_count > 0 {
            (documented_methods as f32 / analysis.method_count as f32) * 100.0
        } else {
            0.0
        };

        if doc_coverage < 80.0 && analysis.method_count > 0 {
            issues.push(Issue {
                file_path: analysis.file_path.clone(),
                issue_type: IssueType::PoorDocumentation,
                description: format!("æ–‡æ¡£è¦†ç›–ç‡ä»…{:.1}%ï¼Œéœ€è¦æ”¹è¿›", doc_coverage),
                severity: Priority::Low,
                suggestion: "ä¸ºæ‰€æœ‰å…¬å…±APIæ–¹æ³•æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£æ³¨é‡Š".to_string(),
                example_fix: Some(generate_documentation_example()),
            });
        }
    }

    issues
}

fn generate_standard_response_example() -> String {
    r#"// æ”¹è¿›å‰
pub async fn search(&self, req: Request) -> SDKResult<BaseResponse<Response>> {
    Transport::request(api_req, &self.config, None).await
}

// æ”¹è¿›å  
pub async fn search(&self, req: Request) -> SDKResult<Response> {
    let api_resp: BaseResponse<Response> = 
        Transport::request(api_req, &self.config, None).await?;
    api_resp.into_result()
}"#
    .to_string()
}

fn generate_builder_example() -> String {
    r#"// ä¸ºå¤æ‚è¯·æ±‚ç»“æ„æ·»åŠ Builder
impl SearchRequest {
    pub fn builder() -> SearchRequestBuilder {
        SearchRequestBuilder::default()
    }
}

impl SearchRequestBuilder {
    pub fn page_size(mut self, size: i32) -> Self {
        self.inner.page_size = Some(size);
        self
    }
    
    pub fn build(self) -> SearchRequest {
        self.inner
    }
}"#
    .to_string()
}

fn generate_documentation_example() -> String {
    r#"/// æœç´¢å·¥ä½œå°è®¿é—®æ•°æ®
///
/// è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å·¥ä½œå°è®¿é—®ç»Ÿè®¡ä¿¡æ¯
///
/// # Arguments
/// * `request` - æœç´¢è¯·æ±‚å‚æ•°
/// * `option` - å¯é€‰çš„è¯·æ±‚é…ç½®
///
/// # Returns
/// è¿”å›è®¿é—®æ•°æ®åˆ—è¡¨
pub async fn search(&self, request: SearchRequest) -> SDKResult<SearchResponse>"#
        .to_string()
}

fn generate_detailed_statistics(results: &HashMap<String, EnhancedFileAnalysis>) {
    let total_files = results.len();
    let total_methods: u32 = results.values().map(|a| a.method_count).sum();
    let total_builders: u32 = results.values().map(|a| a.builder_patterns).sum();
    let total_standard_response: u32 = results.values().map(|a| a.standard_response_usage).sum();

    println!("ğŸ¯ è¯¦ç»†ç»Ÿè®¡:");
    println!("   æ€»æ–‡ä»¶æ•°: {total_files}");
    println!("   æ€»æ–¹æ³•æ•°: {total_methods}");
    println!(
        "   Builderæ¨¡å¼è¦†ç›–ç‡: {:.1}%",
        if total_methods > 0 {
            (total_builders as f32 / total_methods as f32) * 100.0
        } else {
            0.0
        }
    );
    println!(
        "   StandardResponseè¦†ç›–ç‡: {:.1}%",
        if total_methods > 0 {
            (total_standard_response as f32 / total_methods as f32) * 100.0
        } else {
            0.0
        }
    );

    // æŒ‰ä¼˜å…ˆçº§åˆ†ç±»ç»Ÿè®¡
    let mut priority_counts = HashMap::new();
    for analysis in results.values() {
        *priority_counts
            .entry(analysis.improvement_priority.clone())
            .or_insert(0u32) += 1;
    }

    println!("\nğŸ“‹ æ”¹è¿›ä¼˜å…ˆçº§åˆ†å¸ƒ:");
    for (priority, count) in priority_counts {
        println!("   {:?}: {} ä¸ªæ–‡ä»¶", priority, count);
    }
}

fn display_issues(issues: &[Issue]) {
    println!("\nğŸš¨ å‘ç°çš„é—®é¢˜:");
    let mut by_severity: HashMap<Priority, Vec<&Issue>> = HashMap::new();

    for issue in issues {
        by_severity
            .entry(issue.severity.clone())
            .or_default()
            .push(issue);
    }

    for severity in [
        Priority::Critical,
        Priority::High,
        Priority::Medium,
        Priority::Low,
    ] {
        if let Some(issues) = by_severity.get(&severity) {
            println!("\n{:?} çº§é—®é¢˜ ({} ä¸ª):", severity, issues.len());
            for issue in issues.iter().take(3) {
                // åªæ˜¾ç¤ºå‰3ä¸ª
                let file_name = Path::new(&issue.file_path)
                    .file_name()
                    .unwrap_or_default()
                    .to_string_lossy();
                println!("   ğŸ“ {}: {}", file_name, issue.description);
            }
            if issues.len() > 3 {
                println!("   ... è¿˜æœ‰ {} ä¸ªç±»ä¼¼é—®é¢˜", issues.len() - 3);
            }
        }
    }
}

fn generate_enhanced_report(
    results: &HashMap<String, EnhancedFileAnalysis>,
    issues: &[Issue],
    output_path: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    if let Some(parent) = Path::new(output_path).parent() {
        fs::create_dir_all(parent)?;
    }

    let mut report = String::new();

    report.push_str("# APIè®¾è®¡ä¸€è‡´æ€§å¢å¼ºæ£€æŸ¥æŠ¥å‘Š\n\n");
    report.push_str(&format!(
        "ç”Ÿæˆæ—¶é—´: {}\n\n",
        chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
    ));

    // æ‰§è¡Œæ‘˜è¦
    report.push_str("## ğŸ“‹ æ‰§è¡Œæ‘˜è¦\n\n");
    let total_files = results.len();
    let total_methods: u32 = results.values().map(|a| a.method_count).sum();
    let total_issues = issues.len();

    report.push_str(&format!(
        "- **æ£€æŸ¥èŒƒå›´**: {} ä¸ªæœåŠ¡æ–‡ä»¶ï¼Œ{} ä¸ªAPIæ–¹æ³•\n",
        total_files, total_methods
    ));
    report.push_str(&format!(
        "- **å‘ç°é—®é¢˜**: {} ä¸ªéœ€è¦æ”¹è¿›çš„é¡¹ç›®\n",
        total_issues
    ));

    let critical_issues = issues
        .iter()
        .filter(|i| i.severity == Priority::Critical)
        .count();
    let high_issues = issues
        .iter()
        .filter(|i| i.severity == Priority::High)
        .count();

    report.push_str(&format!(
        "- **ä¸¥é‡é—®é¢˜**: {} ä¸ª Criticalï¼Œ{} ä¸ª High ä¼˜å…ˆçº§\n\n",
        critical_issues, high_issues
    ));

    // è¯¦ç»†ç»Ÿè®¡åˆ†æ
    report.push_str("## ğŸ“Š è¯¦ç»†ç»Ÿè®¡åˆ†æ\n\n");
    generate_statistics_section(&mut report, results);

    // é—®é¢˜åˆ†æå’Œå»ºè®®
    report.push_str("## ğŸ” é—®é¢˜åˆ†æå’Œæ”¹è¿›å»ºè®®\n\n");
    generate_issues_section(&mut report, issues);

    // æ”¹è¿›è·¯çº¿å›¾
    report.push_str("## ğŸ—ºï¸ æ”¹è¿›è·¯çº¿å›¾\n\n");
    generate_roadmap_section(&mut report, results, issues);

    fs::write(output_path, report)?;
    Ok(())
}

fn generate_statistics_section(
    report: &mut String,
    results: &HashMap<String, EnhancedFileAnalysis>,
) {
    let total_methods: u32 = results.values().map(|a| a.method_count).sum();
    let total_builders: u32 = results.values().map(|a| a.builder_patterns).sum();
    let total_standard_response: u32 = results.values().map(|a| a.standard_response_usage).sum();

    let sr_coverage = if total_methods > 0 {
        (total_standard_response as f32 / total_methods as f32) * 100.0
    } else {
        0.0
    };

    let builder_coverage = if total_methods > 0 {
        (total_builders as f32 / total_methods as f32) * 100.0
    } else {
        0.0
    };

    report.push_str(&format!(
        "| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | è¾¾æˆç‡ |\n\
         |------|--------|--------|--------|\n\
         | StandardResponseè¦†ç›–ç‡ | {:.1}% | 80% | {:.1}% |\n\
         | Builderæ¨¡å¼è¦†ç›–ç‡ | {:.1}% | 60% | {:.1}% |\n\
         | æ€»APIæ–¹æ³•æ•° | {} | - | - |\n\n",
        sr_coverage,
        (sr_coverage / 80.0) * 100.0,
        builder_coverage,
        (builder_coverage / 60.0) * 100.0,
        total_methods
    ));
}

fn generate_issues_section(report: &mut String, issues: &[Issue]) {
    let mut by_type: HashMap<String, Vec<&Issue>> = HashMap::new();

    for issue in issues {
        let type_name = format!("{:?}", issue.issue_type);
        by_type.entry(type_name).or_default().push(issue);
    }

    for (issue_type, issues) in by_type {
        report.push_str(&format!("### {}\n\n", issue_type));
        report.push_str(&format!("å‘ç° {} ä¸ªç›¸å…³é—®é¢˜:\n\n", issues.len()));

        // æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜çš„è¯¦ç»†ä¿¡æ¯
        for (i, issue) in issues.iter().take(5).enumerate() {
            let file_name = Path::new(&issue.file_path)
                .file_name()
                .unwrap_or_default()
                .to_string_lossy();

            report.push_str(&format!(
                "{}. **{}** ({:?})\n",
                i + 1,
                file_name,
                issue.severity
            ));
            report.push_str(&format!("   - é—®é¢˜: {}\n", issue.description));
            report.push_str(&format!("   - å»ºè®®: {}\n", issue.suggestion));

            if let Some(ref example) = issue.example_fix {
                report.push_str("   - ç¤ºä¾‹ä¿®å¤:\n");
                report.push_str("   ```rust\n");
                report.push_str(example);
                report.push_str("\n   ```\n\n");
            }
        }

        if issues.len() > 5 {
            report.push_str(&format!("... è¿˜æœ‰ {} ä¸ªç±»ä¼¼é—®é¢˜\n\n", issues.len() - 5));
        }
    }
}

fn generate_roadmap_section(
    report: &mut String,
    results: &HashMap<String, EnhancedFileAnalysis>,
    _issues: &[Issue],
) {
    report.push_str("æ ¹æ®åˆ†æç»“æœï¼Œå»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºè¿›è¡Œæ”¹è¿›:\n\n");

    // æŒ‰ä¼˜å…ˆçº§åˆ†ç»„æ–‡ä»¶
    let mut critical_files = Vec::new();
    let mut high_files = Vec::new();
    let mut medium_files = Vec::new();

    for analysis in results.values() {
        match analysis.improvement_priority {
            Priority::Critical => critical_files.push(&analysis.file_path),
            Priority::High => high_files.push(&analysis.file_path),
            Priority::Medium => medium_files.push(&analysis.file_path),
            Priority::Low => {}
        }
    }

    if !critical_files.is_empty() {
        report.push_str("### ğŸš¨ ç¬¬ä¸€é˜¶æ®µ: Critical ä¼˜å…ˆçº§æ–‡ä»¶\n\n");
        for file in critical_files.iter().take(10) {
            let file_name = Path::new(file)
                .file_name()
                .unwrap_or_default()
                .to_string_lossy();
            report.push_str(&format!("- {}\n", file_name));
        }
        report.push('\n');
    }

    if !high_files.is_empty() {
        report.push_str("### âš¡ ç¬¬äºŒé˜¶æ®µ: High ä¼˜å…ˆçº§æ–‡ä»¶\n\n");
        for file in high_files.iter().take(10) {
            let file_name = Path::new(file)
                .file_name()
                .unwrap_or_default()
                .to_string_lossy();
            report.push_str(&format!("- {}\n", file_name));
        }
        report.push('\n');
    }

    if !medium_files.is_empty() {
        report.push_str("### ğŸ“‹ ç¬¬ä¸‰é˜¶æ®µ: Medium ä¼˜å…ˆçº§æ–‡ä»¶\n\n");
        report.push_str(&format!(
            "å‰©ä½™ {} ä¸ªæ–‡ä»¶å¯ä»¥åœ¨åç»­é˜¶æ®µé€æ­¥æ”¹è¿›ã€‚\n\n",
            medium_files.len()
        ));
    }

    report.push_str("### ğŸ¯ æˆåŠŸæ ‡å‡†\n\n");
    report.push_str("- StandardResponseè¦†ç›–ç‡è¾¾åˆ°80%\n");
    report.push_str("- Builderæ¨¡å¼è¦†ç›–ç‡è¾¾åˆ°60%\n");
    report.push_str("- æ‰€æœ‰Criticalå’ŒHighä¼˜å…ˆçº§é—®é¢˜å¾—åˆ°è§£å†³\n");
    report.push_str("- ä¿æŒç°æœ‰æµ‹è¯•é€šè¿‡ç‡100%\n\n");
}
