//! æ€§èƒ½åŸºå‡†æµ‹è¯•ç¤ºä¾‹
//!
//! æ¼”ç¤º open-lark SDK çš„æ€§èƒ½æµ‹è¯•å’Œç›‘æ§åŠŸèƒ½

use serde::Serialize;
use std::time::{Duration, Instant};
use tracing::info;

/// åŸºå‡†æµ‹è¯•é…ç½®
#[derive(Debug, Clone)]
pub struct BenchmarkConfig {
    /// æµ‹è¯•æŒç»­æ—¶é—´
    pub duration: Duration,
    /// å¹¶å‘æ•°é‡
    pub concurrent_requests: usize,
    /// é‡å¤æ¬¡æ•°
    pub iterations: usize,
}

impl Default for BenchmarkConfig {
    fn default() -> Self {
        Self {
            duration: Duration::from_secs(10),
            concurrent_requests: 10,
            iterations: 100,
        }
    }
}

/// åŸºå‡†æµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize)]
pub struct BenchmarkResult {
    /// æµ‹è¯•åç§°
    pub test_name: String,
    /// æ€»è¯·æ±‚æ•°
    pub total_requests: u64,
    /// æˆåŠŸè¯·æ±‚æ•°
    pub successful_requests: u64,
    /// æ€»è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub total_duration_ms: u64,
    /// å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub average_response_time_ms: f64,
    /// ååé‡ï¼ˆè¯·æ±‚/ç§’ï¼‰
    pub throughput_rps: f64,
}

impl BenchmarkResult {
    /// åˆ›å»ºæ–°çš„åŸºå‡†æµ‹è¯•ç»“æœ
    pub fn new(test_name: String) -> Self {
        Self {
            test_name,
            total_requests: 0,
            successful_requests: 0,
            total_duration_ms: 0,
            average_response_time_ms: 0.0,
            throughput_rps: 0.0,
        }
    }

    /// è®¡ç®—ç»Ÿè®¡æ•°æ®
    pub fn calculate_statistics(&mut self, response_times: &mut Vec<u64>) {
        if response_times.is_empty() {
            return;
        }

        let sum: u64 = response_times.iter().sum();
        self.average_response_time_ms = sum as f64 / response_times.len() as f64;

        // è®¡ç®—ååé‡
        if self.total_duration_ms > 0 {
            self.throughput_rps =
                self.total_requests as f64 / (self.total_duration_ms as f64 / 1000.0);
        }
    }

    /// æ‰“å°ç»“æœ
    pub fn print_results(&self) {
        println!("=== {} åŸºå‡†æµ‹è¯•ç»“æœ ===", self.test_name);
        println!("æ€»è¯·æ±‚æ•°: {}", self.total_requests);
        println!("æˆåŠŸè¯·æ±‚: {}", self.successful_requests);
        println!("æ€»è€—æ—¶: {}ms", self.total_duration_ms);
        println!("å¹³å‡å“åº”æ—¶é—´: {:.2}ms", self.average_response_time_ms);
        println!("ååé‡: {:.2} è¯·æ±‚/ç§’", self.throughput_rps);
        println!();
    }
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
pub struct PerformanceBenchmark {
    config: BenchmarkConfig,
}

impl PerformanceBenchmark {
    /// åˆ›å»ºæ–°çš„åŸºå‡†æµ‹è¯•å¥—ä»¶
    pub fn new(config: BenchmarkConfig) -> Self {
        Self { config }
    }

    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»º
    pub fn new_default() -> Self {
        Self::new(BenchmarkConfig::default())
    }

    /// è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
    pub async fn run_all_benchmarks(&self) -> Vec<BenchmarkResult> {
        let mut results = Vec::new();

        info!("å¼€å§‹è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...");

        // HTTPè¯·æ±‚æ€§èƒ½æµ‹è¯•
        results.push(self.benchmark_http_performance().await);

        // å†…å­˜ä½¿ç”¨æµ‹è¯•
        results.push(self.benchmark_memory_usage().await);

        // åºåˆ—åŒ–æ€§èƒ½æµ‹è¯•
        results.push(self.benchmark_serialization_performance().await);

        // å¹¶å‘æ€§èƒ½æµ‹è¯•
        results.push(self.benchmark_concurrent_performance().await);

        // æ‰“å°æ€»ç»“
        self.print_summary(&results);

        results
    }

    /// HTTPè¯·æ±‚æ€§èƒ½æµ‹è¯•
    pub async fn benchmark_http_performance(&self) -> BenchmarkResult {
        let test_name = "HTTPè¯·æ±‚æ€§èƒ½".to_string();
        let mut result = BenchmarkResult::new(test_name.clone());
        let mut response_times = Vec::new();

        info!("å¼€å§‹HTTPè¯·æ±‚æ€§èƒ½æµ‹è¯•...");

        let start_time = Instant::now();
        let end_time = start_time + self.config.duration;

        while Instant::now() < end_time {
            let request_start = Instant::now();

            // æ¨¡æ‹ŸHTTPè¯·æ±‚å»¶è¿Ÿ
            tokio::time::sleep(Duration::from_millis(50)).await;

            let response_time = request_start.elapsed().as_millis() as u64;
            response_times.push(response_time);

            result.total_requests += 1;
            result.successful_requests += 1;

            // æ§åˆ¶è¯·æ±‚é¢‘ç‡
            tokio::time::sleep(Duration::from_millis(10)).await;
        }

        result.total_duration_ms = start_time.elapsed().as_millis() as u64;
        result.calculate_statistics(&mut response_times);
        result.print_results();

        result
    }

    /// å†…å­˜ä½¿ç”¨æµ‹è¯•
    pub async fn benchmark_memory_usage(&self) -> BenchmarkResult {
        let test_name = "å†…å­˜ä½¿ç”¨".to_string();
        let mut result = BenchmarkResult::new(test_name.clone());
        let mut response_times = Vec::new();

        info!("å¼€å§‹å†…å­˜ä½¿ç”¨æµ‹è¯•...");

        let start_time = Instant::now();
        let end_time = start_time + self.config.duration;

        while Instant::now() < end_time {
            let request_start = Instant::now();

            // æ¨¡æ‹Ÿå†…å­˜å¯†é›†æ“ä½œ
            let _data: Vec<u8> = vec![0u8; 1024 * 10]; // 10KB
            tokio::time::sleep(Duration::from_micros(100)).await;

            let response_time = request_start.elapsed().as_millis() as u64;
            response_times.push(response_time);

            result.total_requests += 1;
            result.successful_requests += 1;

            // æ§åˆ¶æ“ä½œé¢‘ç‡
            tokio::time::sleep(Duration::from_millis(20)).await;
        }

        result.total_duration_ms = start_time.elapsed().as_millis() as u64;
        result.calculate_statistics(&mut response_times);
        result.print_results();

        result
    }

    /// åºåˆ—åŒ–æ€§èƒ½æµ‹è¯•
    pub async fn benchmark_serialization_performance(&self) -> BenchmarkResult {
        let test_name = "åºåˆ—åŒ–æ€§èƒ½".to_string();
        let mut result = BenchmarkResult::new(test_name.clone());
        let mut response_times = Vec::new();

        info!("å¼€å§‹åºåˆ—åŒ–æ€§èƒ½æµ‹è¯•...");

        let start_time = Instant::now();
        let end_time = start_time + self.config.duration;

        while Instant::now() < end_time {
            let request_start = Instant::now();

            // æ¨¡æ‹Ÿåºåˆ—åŒ–æ“ä½œ
            let data = "x".repeat(100);
            let _json_str = serde_json::to_string(&data).unwrap_or_default();
            tokio::time::sleep(Duration::from_micros(200)).await;

            let response_time = request_start.elapsed().as_millis() as u64;
            response_times.push(response_time);

            result.total_requests += 1;
            result.successful_requests += 1;

            // æ§åˆ¶æ“ä½œé¢‘ç‡
            tokio::time::sleep(Duration::from_millis(15)).await;
        }

        result.total_duration_ms = start_time.elapsed().as_millis() as u64;
        result.calculate_statistics(&mut response_times);
        result.print_results();

        result
    }

    /// å¹¶å‘æ€§èƒ½æµ‹è¯•
    pub async fn benchmark_concurrent_performance(&self) -> BenchmarkResult {
        let test_name = "å¹¶å‘æ€§èƒ½".to_string();
        let mut result = BenchmarkResult::new(test_name.clone());
        let mut response_times = Vec::new();

        info!("å¼€å§‹å¹¶å‘æ€§èƒ½æµ‹è¯•...");

        let start_time = Instant::now();
        let end_time = start_time + self.config.duration;

        while Instant::now() < end_time {
            let request_start = Instant::now();

            // å¹¶å‘ä»»åŠ¡
            let tasks: Vec<_> = (0..self.config.concurrent_requests)
                .map(|_| async {
                    tokio::time::sleep(Duration::from_millis(10)).await;
                })
                .collect();

            futures_util::future::join_all(tasks).await;

            let response_time = request_start.elapsed().as_millis() as u64;
            response_times.push(response_time);

            result.total_requests += self.config.concurrent_requests as u64;
            result.successful_requests += self.config.concurrent_requests as u64;

            // æ§åˆ¶æµ‹è¯•æ‰¹æ¬¡
            tokio::time::sleep(Duration::from_millis(50)).await;
        }

        result.total_duration_ms = start_time.elapsed().as_millis() as u64;
        result.calculate_statistics(&mut response_times);
        result.print_results();

        result
    }

    /// æ‰“å°æµ‹è¯•æ€»ç»“
    fn print_summary(&self, results: &[BenchmarkResult]) {
        println!("=== æ€§èƒ½åŸºå‡†æµ‹è¯•æ€»ç»“ ===");
        println!("æµ‹è¯•é¡¹ç›®æ•°é‡: {}", results.len());
        println!();

        for result in results {
            println!(
                "{}: ååé‡ {:.2} RPS, å¹³å‡å“åº”æ—¶é—´ {:.2}ms",
                result.test_name, result.throughput_rps, result.average_response_time_ms
            );
        }

        // è®¡ç®—å¹³å‡å€¼
        let avg_throughput =
            results.iter().map(|r| r.throughput_rps).sum::<f64>() / results.len() as f64;
        let avg_response_time = results
            .iter()
            .map(|r| r.average_response_time_ms)
            .sum::<f64>()
            / results.len() as f64;

        println!("\nå¹³å‡æ€§èƒ½æŒ‡æ ‡:");
        println!("  å¹³å‡ååé‡: {:.2} RPS", avg_throughput);
        println!("  å¹³å‡å“åº”æ—¶é—´: {:.2} ms", avg_response_time);
        println!();
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt::init();

    let config = BenchmarkConfig {
        duration: Duration::from_secs(10),
        concurrent_requests: 20,
        iterations: 100,
    };

    let benchmark = PerformanceBenchmark::new(config);
    let results = benchmark.run_all_benchmarks().await;

    // è¾“å‡ºJSONæ ¼å¼ç»“æœ
    println!("=== JSONæ ¼å¼ç»“æœ ===");
    println!("{}", serde_json::to_string_pretty(&results)?);

    println!("ğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼");
    println!("âœ… æ‰€æœ‰æµ‹è¯•å·²å®Œæˆï¼ŒæŸ¥çœ‹ä¸Šè¿°ç»“æœäº†è§£æ€§èƒ½æŒ‡æ ‡");

    Ok(())
}
