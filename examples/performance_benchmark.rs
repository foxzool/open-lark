//! HTTPå®¢æˆ·ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•ç¤ºä¾‹
//!
//! æ­¤ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ï¼š
//! 1. ä½¿ç”¨ä¸åŒçš„HTTPå®¢æˆ·ç«¯é…ç½®
//! 2. è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
//! 3. æ¯”è¾ƒé…ç½®æ€§èƒ½å·®å¼‚
//! 4. é€‰æ‹©æœ€ä½³é…ç½®
//!
//! è¿è¡Œæ–¹å¼ï¼š
//! ```bash
//! cargo run --example performance_benchmark --features=benchmarks
//! ```

use open_lark::core::{
    config::Config,
    performance::{BenchmarkConfig, ClientComparison, HttpBenchmark, OptimizedHttpConfig},
};
use std::collections::HashMap;
use tracing::{info, Level};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—è®°å½•
    tracing_subscriber::fmt().with_max_level(Level::INFO).init();

    info!("ğŸš€ å¼€å§‹HTTPå®¢æˆ·ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•");

    // æµ‹è¯•é…ç½®
    let benchmark_config = BenchmarkConfig {
        concurrent_connections: 20,
        requests_per_connection: 50,
        warmup_requests: 10,
        target_url: "https://httpbin.org/json".to_string(),
        headers: {
            let mut headers = HashMap::new();
            headers.insert("User-Agent".to_string(), "open-lark-benchmark".to_string());
            headers
        },
    };

    // é…ç½®1: é»˜è®¤é…ç½®
    let default_config = OptimizedHttpConfig::default();

    // é…ç½®2: ç”Ÿäº§ç¯å¢ƒé…ç½®
    let production_config = OptimizedHttpConfig::production();

    // é…ç½®3: é«˜ååé‡é…ç½®
    let high_throughput_config = OptimizedHttpConfig::high_throughput();

    // é…ç½®4: ä½å»¶è¿Ÿé…ç½®
    let low_latency_config = OptimizedHttpConfig::low_latency();

    // é…ç½®5: è‡ªå®šä¹‰æé€Ÿé…ç½®
    let ultra_fast_config = OptimizedHttpConfig {
        pool_max_idle_per_host: 300,
        pool_idle_timeout: std::time::Duration::from_secs(300),
        connect_timeout: std::time::Duration::from_millis(1000),
        request_timeout: std::time::Duration::from_secs(5),
        http2_prior_knowledge: true,
        http2_adaptive_window: true,
        gzip: false,
        brotli: false,
        user_agent: "open-lark-ultra-fast".to_string(),
    };

    // è¦æµ‹è¯•çš„é…ç½®åˆ—è¡¨
    let configs = vec![
        ("é»˜è®¤é…ç½®", default_config),
        ("ç”Ÿäº§ç¯å¢ƒ", production_config),
        ("é«˜ååé‡", high_throughput_config),
        ("ä½å»¶è¿Ÿ", low_latency_config),
        ("æé€Ÿè‡ªå®šä¹‰", ultra_fast_config),
    ];

    info!("ğŸ“Š å¼€å§‹é…ç½®æ€§èƒ½æ¯”è¾ƒæµ‹è¯•...");

    // è¿è¡Œé…ç½®æ¯”è¾ƒ
    match ClientComparison::compare_configurations(configs, benchmark_config.clone()).await {
        Ok(results) => {
            info!("âœ… æ‰€æœ‰é…ç½®æµ‹è¯•å®Œæˆ");

            // è¾“å‡ºæ¨èé…ç½®
            print_recommendations(&results);
        }
        Err(e) => {
            eprintln!("âŒ é…ç½®æ¯”è¾ƒæµ‹è¯•å¤±è´¥: {}", e);
        }
    }

    // æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨ä¼˜åŒ–é…ç½®
    info!("ğŸ”§ æ¼”ç¤ºåœ¨Configä¸­é›†æˆä¼˜åŒ–é…ç½®...");
    demonstrate_config_integration().await?;

    info!("ğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

/// æ‰“å°é…ç½®æ¨è
fn print_recommendations(results: &[(String, open_lark::core::performance::PerformanceMetrics)]) {
    info!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    info!("â•‘                            ğŸ“Š é…ç½®æ¨è                                  â•‘");
    info!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    if let Some((best_throughput_name, best_throughput)) = results.iter().max_by(|a, b| {
        a.1.requests_per_second
            .partial_cmp(&b.1.requests_per_second)
            .unwrap()
    }) {
        info!(
            "ğŸ† æœ€ä½³ååé‡: {} ({:.1} RPS)",
            best_throughput_name, best_throughput.requests_per_second
        );
        info!("   æ¨èåœºæ™¯: æ‰¹é‡æ•°æ®å¤„ç†ã€åå°åŒæ­¥ä»»åŠ¡");
    }

    if let Some((best_latency_name, best_latency)) = results.iter().min_by(|a, b| {
        a.1.avg_response_time_ms
            .partial_cmp(&b.1.avg_response_time_ms)
            .unwrap()
    }) {
        info!(
            "ğŸš€ æœ€ä½å»¶è¿Ÿ: {} ({:.2}ms å¹³å‡å»¶è¿Ÿ)",
            best_latency_name, best_latency.avg_response_time_ms
        );
        info!("   æ¨èåœºæ™¯: å®æ—¶APIè°ƒç”¨ã€ç”¨æˆ·äº¤äº’åŠŸèƒ½");
    }

    if let Some((most_reliable_name, most_reliable)) = results
        .iter()
        .min_by(|a, b| a.1.error_rate.partial_cmp(&b.1.error_rate).unwrap())
    {
        info!(
            "ğŸ›¡ï¸  æœ€é«˜å¯é æ€§: {} ({:.2}% é”™è¯¯ç‡)",
            most_reliable_name, most_reliable.error_rate
        );
        info!("   æ¨èåœºæ™¯: å…³é”®ä¸šåŠ¡æµç¨‹ã€é‡‘èäº¤æ˜“");
    }

    // æä¾›å…·ä½“çš„ä½¿ç”¨å»ºè®®
    info!("");
    info!("ğŸ“‹ ä½¿ç”¨å»ºè®®:");
    info!("   1. å¼€å‘/æµ‹è¯•ç¯å¢ƒ: ä½¿ç”¨é»˜è®¤é…ç½®");
    info!("   2. ç”Ÿäº§ç¯å¢ƒ (é€šç”¨): ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒé…ç½®");
    info!("   3. é«˜å¹¶å‘åœºæ™¯: ä½¿ç”¨é«˜ååé‡é…ç½®");
    info!("   4. å®æ—¶åº”ç”¨: ä½¿ç”¨ä½å»¶è¿Ÿé…ç½®");
    info!("   5. ç‰¹æ®Šéœ€æ±‚: åŸºäºåŸºå‡†æµ‹è¯•ç»“æœå®šåˆ¶é…ç½®");
}

/// æ¼”ç¤ºåœ¨Configä¸­é›†æˆä¼˜åŒ–é…ç½®
async fn demonstrate_config_integration() -> Result<(), Box<dyn std::error::Error>> {
    info!("åˆ›å»ºä½¿ç”¨ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–é…ç½®çš„SDKé…ç½®...");

    // æ–¹å¼1: ä½¿ç”¨é¢„è®¾é…ç½®
    let config = Config::builder()
        .app_id("test_app_id")
        .app_secret("test_app_secret")
        .production_http_client()?
        .build();

    info!("âœ… ç”Ÿäº§ç¯å¢ƒé…ç½®åˆ›å»ºæˆåŠŸ");

    // æ–¹å¼2: ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
    let custom_http_config = OptimizedHttpConfig {
        pool_max_idle_per_host: 150,
        pool_idle_timeout: std::time::Duration::from_secs(120),
        connect_timeout: std::time::Duration::from_secs(3),
        request_timeout: std::time::Duration::from_secs(20),
        http2_prior_knowledge: true,
        http2_adaptive_window: true,
        gzip: true,
        brotli: true,
        user_agent: "my-custom-app/1.0".to_string(),
    };

    let _custom_config = Config::builder()
        .app_id("test_app_id")
        .app_secret("test_app_secret")
        .optimized_http_client(custom_http_config)?
        .build();

    info!("âœ… è‡ªå®šä¹‰ä¼˜åŒ–é…ç½®åˆ›å»ºæˆåŠŸ");

    // è¾“å‡ºé…ç½®ä¿¡æ¯
    info!("é…ç½®å¼•ç”¨è®¡æ•°: {}", config.reference_count());
    info!("HTTPå®¢æˆ·ç«¯æ± é…ç½®: å·²ä¼˜åŒ–");

    Ok(())
}

/// è¿è¡Œå•ä¸ªé…ç½®çš„è¯¦ç»†åŸºå‡†æµ‹è¯•
#[allow(dead_code)]
async fn run_detailed_benchmark() -> Result<(), Box<dyn std::error::Error>> {
    info!("ğŸ” è¿è¡Œè¯¦ç»†åŸºå‡†æµ‹è¯•...");

    let config = OptimizedHttpConfig::production();
    let client = config.build_client()?;

    let benchmark_config = BenchmarkConfig {
        concurrent_connections: 50,
        requests_per_connection: 200,
        warmup_requests: 50,
        target_url: "https://httpbin.org/json".to_string(),
        headers: HashMap::new(),
    };

    let benchmark = HttpBenchmark::new(client, benchmark_config);
    let metrics = benchmark
        .run_benchmark()
        .await
        .map_err(|e| format!("Benchmark failed: {}", e))?;

    info!("ğŸ“ˆ è¯¦ç»†åŸºå‡†æµ‹è¯•ç»“æœ:");
    metrics.print_report();

    Ok(())
}
