#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ä¿®å¤server-docsæ ¼å¼çš„æ–‡æ¡£URL

å°†æ‰€æœ‰server-docsæ ¼å¼çš„URLæ›¿æ¢ä¸ºä»å®˜æ–¹APIæ•°æ®ä¸­è·å–çš„æ­£ç¡®URL
"""

import csv
import re
import os
from pathlib import Path
from typing import Dict, List, Tuple

def load_official_apis():
    """åŠ è½½å®˜æ–¹APIæ•°æ®"""
    official_apis = {}

    csv_path = Path(__file__).parent.parent / "reports" / "official_apis_by_module.csv"
    if not csv_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å®˜æ–¹APIæ•°æ®æ–‡ä»¶ {csv_path}")
        return {}

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            module = row['æ¨¡å—']
            method = row['HTTPæ–¹æ³•']
            endpoint = row['ç«¯ç‚¹è·¯å¾„']
            doc_url = row['æ–‡æ¡£URL']
            version = row['ç‰ˆæœ¬']
            name = row['APIåç§°']
            description = row['æè¿°']

            # åˆ›å»ºAPIæ ‡è¯†ç¬¦ç”¨äºåŒ¹é…
            api_key = f"{method}:{endpoint}"

            if api_key not in official_apis:
                official_apis[api_key] = []

            official_apis[api_key].append({
                'module': module,
                'method': method,
                'endpoint': endpoint,
                'doc_url': doc_url,
                'version': version,
                'name': name,
                'description': description
            })

    print(f"âœ… æˆåŠŸåŠ è½½å®˜æ–¹APIæ•°æ®: {len(official_apis)} ä¸ªç«¯ç‚¹")
    return official_apis

def find_server_docs_files():
    """æŸ¥æ‰¾æ‰€æœ‰åŒ…å«server-docs URLçš„æ–‡ä»¶"""
    base_path = Path(__file__).parent.parent / "src" / "service"
    files_with_server_docs = []

    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.endswith('.rs') and not file.endswith('.bak'):
                file_path = Path(root) / file
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if 'https://open.feishu.cn/document/server-docs' in content:
                            files_with_server_docs.append(file_path)
                except Exception as e:
                    print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    return files_with_server_docs

def extract_api_info_from_file(file_path: Path) -> List[Dict]:
    """ä»æ–‡ä»¶ä¸­æå–APIä¿¡æ¯"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return []

    # æŸ¥æ‰¾æ‰€æœ‰server-docs URL
    server_docs_pattern = r'https://open\.feishu\.cn/document/server-docs/([^\s>]+)'
    matches = re.finditer(server_docs_pattern, content)

    apis_found = []
    for match in matches:
        old_url = match.group(0)
        api_path = match.group(1)

        # å°è¯•ä»æ–‡ä»¶è·¯å¾„æ¨æ–­APIä¿¡æ¯
        file_str = str(file_path)
        module_info = file_path.parts[-3] if len(file_path.parts) >= 3 else "unknown"
        service_info = file_path.parts[-2] if len(file_path.parts) >= 2 else "unknown"

        apis_found.append({
            'file_path': file_path,
            'old_url': old_url,
            'api_path': api_path,
            'module': module_info,
            'service': service_info,
            'line_content': content[match.start():match.end()+50]  # åŒ…å«ä¸€äº›ä¸Šä¸‹æ–‡
        })

    return apis_found

def find_matching_official_url(api_info: Dict, official_apis: Dict) -> str:
    """ä¸ºAPIä¿¡æ¯æŸ¥æ‰¾åŒ¹é…çš„å®˜æ–¹URL"""
    api_path = api_info['api_path']
    module = api_info['module']

    # æ ¹æ®APIè·¯å¾„æ¨æ–­HTTPæ–¹æ³•å’Œç«¯ç‚¹
    # è¿™é‡Œä½¿ç”¨å¯å‘å¼æ–¹æ³•æ¥åŒ¹é…
    for api_key, api_list in official_apis.items():
        method, endpoint = api_key.split(':', 1)

        # æ£€æŸ¥æ¨¡å—æ˜¯å¦åŒ¹é…
        if api_list and api_list[0]['module'].lower() == module.lower():
            # æ£€æŸ¥APIè·¯å¾„æ˜¯å¦åŒ¹é…
            if any(keyword in endpoint.lower() for keyword in api_path.lower().split('/')):
                return api_list[0]['doc_url']

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
    for api_key, api_list in official_apis.items():
        if api_list:
            doc_url = api_list[0]['doc_url']
            # æ£€æŸ¥URLè·¯å¾„æ˜¯å¦åŒ…å«ç›¸ä¼¼çš„å…³é”®è¯
            if any(keyword in doc_url.lower() for keyword in api_path.lower().split('/')):
                return doc_url

    return None

def fix_file_urls(file_path: Path, apis_to_fix: List[Dict], official_apis: Dict) -> int:
    """ä¿®å¤å•ä¸ªæ–‡ä»¶ä¸­çš„URL"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return 0

    content_modified = content
    fixes_made = 0

    # æŒ‰ç…§URLé•¿åº¦é™åºå¤„ç†ï¼Œé¿å…çŸ­URLåŒ¹é…é•¿URLçš„ä¸€éƒ¨åˆ†
    apis_to_fix.sort(key=lambda x: len(x['old_url']), reverse=True)

    for api_info in apis_to_fix:
        old_url = api_info['old_url']
        correct_url = find_matching_official_url(api_info, official_apis)

        if correct_url and old_url in content_modified:
            content_modified = content_modified.replace(old_url, correct_url)
            fixes_made += 1
            print(f"   âœ… ä¿®å¤: {old_url[:60]}... â†’ {correct_url[:60]}...")
        elif not correct_url:
            print(f"   âš ï¸  æœªæ‰¾åˆ°åŒ¹é…: {old_url[:60]}...")

    # å†™å›æ–‡ä»¶
    if fixes_made > 0:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content_modified)
            print(f"   ğŸ“ {file_path.name}: {fixes_made} ä¸ªURLå·²ä¿®å¤")
        except Exception as e:
            print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return 0

    return fixes_made

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ‰¹é‡ä¿®å¤server-docsæ ¼å¼çš„æ–‡æ¡£URL")
    print("=" * 50)

    # 1. åŠ è½½å®˜æ–¹APIæ•°æ®
    official_apis = load_official_apis()
    if not official_apis:
        return

    # 2. æŸ¥æ‰¾æ‰€æœ‰åŒ…å«server-docs URLçš„æ–‡ä»¶
    print(f"\nğŸ” æŸ¥æ‰¾åŒ…å«server-docs URLçš„æ–‡ä»¶...")
    files_to_process = find_server_docs_files()

    if not files_to_process:
        print("âœ… æ²¡æœ‰æ‰¾åˆ°éœ€è¦ä¿®å¤çš„æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")

    # 3. åˆ†ææ¯ä¸ªæ–‡ä»¶çš„APIä¿¡æ¯
    total_fixes = 0
    processed_files = 0

    for file_path in files_to_process:
        print(f"\nğŸ”§ å¤„ç†æ–‡ä»¶: {file_path.relative_to(Path(__file__).parent.parent)}")

        # æå–APIä¿¡æ¯
        apis_to_fix = extract_api_info_from_file(file_path)

        if not apis_to_fix:
            print("   âš ï¸  æœªæ‰¾åˆ°APIä¿¡æ¯")
            continue

        print(f"   ğŸ“Š å‘ç° {len(apis_to_fix)} ä¸ªAPIéœ€è¦ä¿®å¤")

        # ä¿®å¤URL
        fixes = fix_file_urls(file_path, apis_to_fix, official_apis)
        total_fixes += fixes
        processed_files += 1

    print(f"\nğŸ‰ å®Œæˆï¼")
    print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {processed_files}")
    print(f"ğŸ”§ ä¿®å¤URLæ•°: {total_fixes}")

    # 4. éªŒè¯ç»“æœ
    print(f"\nğŸ” éªŒè¯ä¿®å¤ç»“æœ...")
    try:
        result = os.popen('python3 scripts/doc_url_checker_simple.py --no-url-check | grep "æ ¼å¼é”™è¯¯"').read()
        if result.strip():
            print(f"   ğŸ“Š å½“å‰çŠ¶æ€: {result.strip()}")
        else:
            print("   âœ… æ‰€æœ‰æ ¼å¼é”™è¯¯å·²ä¿®å¤")
    except:
        print(f"   âš ï¸  æ— æ³•è·å–éªŒè¯ä¿¡æ¯")

if __name__ == "__main__":
    main()